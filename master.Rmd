---
title: 'Simulation Study: General Setting'
output: html_document
date: "2024-10-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Libraries
library(data.table)
library(survival)
#install.packages("rtmle")
#devtools::install_github("tagteam/rtmle")
library(rtmle)
library(ggplot2)
library(microbenchmark)
theme_set(theme_bw())
```


# The Simulation Function

## Simulationg operation data

Using the wrapper

```{r}
data <- sim_op_data(50)
plot_event_data(data) 
```

Or using the general function

```{r}
N <- 100
eta <- c(0.1, 0.1, 0.1, 0.1)
nu <- c(1.1, 1.1, 1.1, 1.1)
# Effect on Operation
beta0 <- c(3, 0, 1, 3)
# Effect on Death
beta1 <- c(0, 0, -1, 1)
# Effect on Censoring
beta2 <- c(3, 0, 1, 1)
# Effect on time varying covariate
beta3 <- c(3, 0, -1, 0.5)

beta <- cbind(beta0, beta1, beta2, beta3)

# Checking whether the simulations work
data <- vec_sim_event_data(N = N, beta = beta, eta = eta, nu = nu)
plot_event_data(data) 
```

## Simulationg survival data
Simulation and plot

```{r}
data <- sim_surv_data(100)
plot_event_data(data, title = "Survival Data")
```

Model fit

```{r}
beta <- matrix(rnorm(4,0,1), ncol = 2, nrow = 2)
data <- sim_surv_data(N = 6000, beta = beta)

survfit_death <- coxph(Surv(Time, Delta == 1) ~ L0 + A, data = data)
coefficients(survfit_death); beta[,1]
confint(survfit_death)

survfit_cens <- coxph(Surv(Time, Delta == 2) ~ L0 + A, data = data)
coefficients(survfit_cens); beta[,2]
confint(survfit_cens)
```

## Simulating competing risk data

```{r}
data <- sim_comp_risk_data(50)
plot_event_data(data, title = "Competing Risk Data")
```

Model fit

```{r}
beta <- matrix(rnorm(6,0,1), ncol = 3, nrow = 2)
data <- sim_comp_risk_data(N = 10000, beta = beta)

survfit_proc1 <- coxph(Surv(Time, Delta == 0) ~ L0 + A, data = data)
coefficients(survfit_proc1); beta[,1]
confint(survfit_proc1)

survfit_proc2 <- coxph(Surv(Time, Delta == 1) ~ L0 + A, data = data)
coefficients(survfit_proc2); beta[,2]
confint(survfit_proc2)

survfit_cens <- coxph(Surv(Time, Delta == 2) ~ L0 + A, data = data)
coefficients(survfit_cens); beta[,3]
confint(survfit_cens)
```

### Fitting models to the operation setting

```{r}
# Generating data
N <- 5000
beta <- matrix(rnorm(16,0,1), ncol = 4, nrow = 4)
data_test <- sim_op_data(N = N, beta = beta)
#data_test <- sim_event_data(N = N, beta = beta)

# Transform data into tstart tstop format
data_int <- trans_int_data(data_test)

# Fit models
survfit_oper <- coxph(Surv(tstart, tstop, Delta == 0) ~ L0 + k + A, data = data_int, cluster = ID)
survfit_death <- coxph(Surv(tstart, tstop, Delta == 1) ~ L0 + k + A + L, data = data_int, cluster = ID)
survfit_cens <- coxph(Surv(tstart, tstop, Delta == 2) ~ L0 + k + A + L, data = data_int, cluster = ID)
survfit_cov <- coxph(Surv(tstart, tstop, Delta == 3) ~ L0 + k + A, data = data_int, cluster = ID)
confint(survfit_oper); c(beta[1,1], (beta[2,1] + beta[4,1]), beta[3,1])
confint(survfit_death); beta[,2]
confint(survfit_cens); beta[,3]
confint(survfit_cov); beta[,4]

# Visualizing the confidence intervals

CIs <- cbind("Par" = c("oper_L0", "oper_k", "oper_A", "death_L0", "death_k", "death_A", "death_L",
                       "cens_L0", "cens_k", "cens_A", "cens_L","cov_L0", "cov_k", "cov_A" ),
           rbind(confint(survfit_oper), confint(survfit_death), confint(survfit_cens),confint(survfit_cov)))

rownames(CIs) <- NULL
colnames(CIs) <- c("Par", "Lower", "Upper")
CIs <- data.table(CIs)

CIs[, True_val := c(beta[1,1], (beta[2,1] + beta[4,1]), beta[3,1],
               beta[,2],
               beta[,3],
               beta[1:3,4])]

CIs$Lower <- as.numeric(CIs$Lower)
CIs$Upper <- as.numeric(CIs$Upper)


ggplot(data = CIs)+
  geom_point(aes(y = Par, x = Lower))+
  geom_point(aes(y = Par, x = Upper))+
  geom_point(aes(y = Par, x = True_val, col = "Estimate"))+
  scale_color_manual(values = c("Estimate" = "red"))+
  geom_segment(aes(y = Par, yend = Par, x = Lower, xend = Upper))

```

## Vectorizing improves the speed

### Benchmarking

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
set.seed(4027)

sim_bench <- bench::press(
  n = 2^(5:10),
  {
    bench::mark(
      "Vectorized" =  vec_sim_event_data(n),
      "Naive" = sim_event_data(n),
      check = FALSE
    )
  }
)

sim_bench <- data.table(sim_bench)
sim_bench[,expr := as.character(expression)] 
sim_bench[,median := as.numeric(median)]

ggplot(data = sim_bench,aes(n, median, color = expr)) + 
  geom_point() + scale_y_log10() +
  geom_line() + labs(y = "time (ms)")
```



### Profiling

```{r}
library(profvis)

profvis({
  
  vec_sim_event_data <- function(N,                  # Number of individuals
                           beta = NULL,            # Effects
                           eta = rep(0.1,4),       # Shape parameters
                           nu = rep(1.1,4),        # Scale parameters
                           at_risk = NULL,         # Function defining the setting
                           term_deltas = c(1,2)    # Terminal events
                           )
    {
    ID <- NULL
    if(is.null(beta)){
      beta <- matrix(0, nrow = 4, ncol = 4)
    }
  
  
    if(is.null(at_risk)){
      at_risk <- function(i) {
        return(c(
          # You are only at risk for an operation if you have not had an operation yet
          as.numeric(k == 0 | (k == 1 & L[i] == 1)),
          # If you have not died yet or been censored yet, you are at risk for dying or being censored
          1,1,
          # You are only at risk for a change in the covariate process if you have not had a change yet
          as.numeric(L[i] == 0)))
    }}
  
    # Events
    x <- 1:ncol(beta)
  
    # Intensities
    phi <- function(i) {
      exp(L0[i] * beta[1,] + k * beta[2,] + A[i] * beta[3,] + L[i] * beta[4,])
    }
  
    lambda <- function(t, i) {
      at_risk(i) * eta * nu * t ^ (nu - 1) * phi(i)
    }
  
    # Summed cumulative hazard
    sum_cum_haz <- function(u, t, i) {
      sum(at_risk(i) * eta * phi(i) * ((t + u) ^ nu - t ^ nu))
    }
  
    # Inverse summed cumulative hazard function
    inverse_sc_haz <- function(p, t, i, lower_bound = 10^-15, upper_bound = 100) {
      root_function <- function(u) sum_cum_haz(u, t, i) - p
      stats::uniroot(root_function, lower = lower_bound, upper = upper_bound)$root
    }
  
    # Event probabilities
    probs <- function(t, i){
      probs <- lambda(t, i)
      summ <- sum(probs)
      probs / summ
    }
  
    # Draw
    L0 <- stats::runif(N)
    A <- stats::rbinom(N, 1, 0.5)
  
    # Initialize
    T_k <- rep(0,N)
    Delta <- -1
    L <- rep(0, N)
    k <- 0
    alive <- 1:N
  
    res <- data.table()
  
    while(length(alive) != 0){
      # Simulate time
      V <- stats::runif(N)
      W <- sapply(alive, function(i) inverse_sc_haz(-log(V)[i], T_k[i], i))
      T_k[alive] <- T_k[alive] + W
  
      # Simulate event
      Deltas <- sapply(alive, function(i) sample(x, size = 1, prob = probs(T_k[i], i)) - 1)
  
      kth_event <- data.table(ID = alive,
                 Time = T_k[alive],
                 Delta = Deltas,
                 L0 = L0[alive],
                 L = L[alive],
                 A = A[alive])
  
      res <- rbind(res, kth_event)
  
      # Update number of events and covariate change
      k <- k + 1
      L[alive][Deltas == 3] <- 1
  
      # Who is still alive and uncensored?
      alive <- alive[! Deltas %in% term_deltas]
    }
  
    return(res[order(ID)])
  }
  
  vec_sim_event_data(1000)
})

```


The time is spent on
- Finding the inverse. But I dont think we can find an analytical expression? 
- Using sapply
- Computing the phi function
- Look into implementing parts in C++

# Interventions

1. Simulate

```{r}
N <- 5000
beta <- matrix(rnorm(16,0,1), ncol = 4, nrow = 4)
data_int <- sim_op_data(N = N, beta = beta)
```

2. Fit a Weibull 

```{r}
data_int[, k:= ave(ID, ID, FUN = seq_along) - 1]
survfit_op <- survreg(Surv(Time, Delta == 0) ~ L0 + k + A, data = data_int, dist='weibull')
survfit_death <- survreg(Surv(Time, Delta == 1) ~ L0 + k + A + L, data = data_int, dist='weibull')
survfit_cens <- survreg(Surv(Time, Delta == 2) ~ L0 + k + A + L, data = data_int, dist='weibull')
survfit_cov <- survreg(Surv(Time, Delta == 3) ~ L0 + k + A, data = data_int, dist='weibull')
```

3. Estimate parameters

```{r}
shape_est <- c(1/survfit_op$scale, 1/survfit_death$scale, 1/survfit_cens$scale, 1/survfit_cov$scale) 
shape_est; 1.1
scale_est <- c(1/exp(survfit_op$coefficients[1]), 1/exp(survfit_death$coefficients[1]), 
               1/exp(survfit_cens$coefficients[1]), 1/exp(survfit_cov$coefficients[1])) 
scale_est; 0.1
```
4. Simulate new data using the estimated parameters - without censoring (?)

To do: implement correctly!

```{r}
sim_obs <- sim_op_data(N = N, beta = beta, eta = scale_est, nu = shape_est)
```

5. Estimate causal effects

To do: implement correctly!

```{r}
mean(sim_obs[sim_obs$Delta == 0,]$Time) - mean(sim_int[sim_int$Delta == 0,]$Time)
mean(sim_obs[sim_obs$Delta == 1,]$Time) - mean(sim_int[sim_int$Delta == 1,]$Time)
mean(sim_obs[sim_obs$Delta == 2,]$Time) - mean(sim_int[sim_int$Delta == 2,]$Time)
```

# Old stuff

### Simulation function

The simulation function is a function of
- Number of individuals: `N`.

- The effect of the baseline covariates and $k$ and on the different intensities: $\beta^x \in \mathbb{R}^{4}$ where $x \in X$. This input, `beta`, should be given as a matrix where each column corresponds to an event $x \in X$. The first row is the effect of the baseline covariate $L_0$, the second row is the effect of $k$, the third row is the effect of treatment $A$, and the fourth row is the effect of time varying covariate $L_1$. 

- The shape `eta` and scale `nu` parameters $(\eta^x)_{x \in X} \in \mathbb{R}^{|X|}$ and $(\nu^x)_{x \in X} \in \mathbb{R}^{|X|}$

- The at risk function `at_risk_func`: an indicator function indicating whether the individual is at risk for the event $x$ at time $t$.

- The terminal events `Delta_Term`: a vector of the terminal events.



### Notation

We use the following notation. 

$x \in \{1,...,m}$ denotes the event type. $x=0$ corresponds to the operation event, $x=1$ to the censoring event, $x=2$ to the death event, $x = 3$ corresponds to a change in the covariate process (e.g. a worsening in condition). 
