---
title: 'Benschmarking and profiling'
output: html_document
date: "2024-10-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Libraries
library(data.table)
library(survival)
library(simevent)
library(ggplot2)
library(microbenchmark)
theme_set(theme_bw())
```

# Optimizing the simulation algorithm

```{r}
simEventRFOld <- function(N,
                       RF_fit,
                       event_names = NULL,
                       L0_old,
                       A0_old,
                       n_event_max = c(1,1),
                       term_events = 1,
                       intervention1 = NULL,
                       intervention2 = NULL) {

  ID <- NULL

  # Initialize
  alive <- 1:N                                            # Vector for keeping track of who is alive
  num_alive <- N                                          # Number of alive individuals
  T_k <- rep(0, N)                                        # Last event time

  # Data frame for storing data
  sim_data <- data.frame(L0 = sample(L0_old, N, TRUE),
                         A0 = sample(A0_old, N, TRUE))
  if(!is.null(event_names)) for (name in event_names) sim_data[[name]] <- 0

  # List for results
  res_list <- vector("list", sum(n_event_max))            # For results
  idx <- 1                                                # Index

  # The cumulative hazard and inverse cumulative hazard
  y.pred <- predict(RF_fit, sim_data)                     # Cumulative hazard for simulated data
  times <-  c(0,y.pred$time.interest)                     # Time points

  num_events <- if(is.na(dim(y.pred$chf)[3])) 1 else dim(y.pred$chf)[3]         # Number of events
  if(!is.null(event_names)) for (name in event_names) sim_data[[name]] <- 0 else
    for (name in paste0("N", 1:num_events)) sim_data[[name]] <- 0

  # Defining the cumulativ hazard and the inverse cumulative hazard
  cumhaz_fn <- function(t, i, j){
    cumhazz <-  if(num_events == 1) y.pred$chf else y.pred$chf[,,j]
    idx <- findInterval(t, times, checkSorted = F)
    t1 <- times[idx]; t2 <- times[idx + 1]
    y1 <- cumhazz[cbind(i,idx)]; y2 <- cumhazz[cbind(i,(idx + 1))]
    y1 + (t - t1) * (y2 - y1) / (t2 - t1)
  }

  invcumhaz_fn <- function(p, i, j){
    cumhazz <-  if(num_events == 1) y.pred$chf else y.pred$chf[,,j]
    idx <- sapply(1:length(i), FUN = function(k) findInterval(p[k], cumhazz[i[k],], checkSorted = F))
    idx[idx == ncol(cumhazz)] <- ncol(cumhazz) - 1
    p1 <- cumhazz[cbind(i, idx)]; p2 <- cumhazz[cbind(i,idx + 1)]
    y1 <- times[idx]; y2 <- times[idx + 1]
    # If the cumulative hazard flattens, we choose the smallest time
    y1 + ifelse(p1 == p2, 0, (p - p1) * (y2 - y1) / (p2 - p1))
  }

  # Loop
  while(num_alive != 0){
    # Calculate the cumulative intensity per individual per event
    cum_int_Tk <- matrix(nrow = num_alive, ncol = num_events)
    for(j in seq_len(num_events)) {
      cum_int_Tk[,j] <- cumhaz_fn(T_k, alive, j)
    }

    # Simulate the uniform random variable
    U <- matrix(-log(stats::runif(num_alive * num_events)), ncol = num_events)  # matrix for the random draws
    V <- U + cum_int_Tk

    # Find the event times
    event_times <- matrix(nrow = num_alive, ncol = num_events)
    for(j in seq_len(num_events)) {
      event_times[,j] <- invcumhaz_fn(V[,j], alive, j)
    }

    # How many times can you experience the various events?
    for(j in seq_len(num_events)){
      event_times[sim_data[, (2+j)] == n_event_max[j], j] <- Inf
    }

    # The next event is the minimum of these events
    T_k <- apply(event_times, 1, min)
    Deltas <- apply(event_times, 1, which.min)

    # Update event counts
    sim_data[cbind(seq_len(num_alive), Deltas + 2)] <- sim_data[cbind(seq_len(num_alive), Deltas + 2)] + 1

    # Store data
    kth_event <- data.table(ID = alive,
                            Time = T_k,
                            Delta = Deltas)

    res_list[[idx]] <- cbind(kth_event, data.table::as.data.table(sim_data))
    idx <- idx + 1

    # Who is still alive?
    alive <- alive[!(Deltas %in% term_events)]
    num_alive <- length(alive)
    # For the next iteration we only keep data from individuals alive
    T_k <- T_k[!(Deltas %in% term_events)]
    sim_data <- sim_data[!(Deltas %in% term_events), , drop = FALSE]
  }

  res <- data.table::rbindlist(res_list)
  setkey(res, ID)
  return(res)
}
```


```{r}
profvis::profvis({
func1 <-  function(N,
                       RF_fit,
                       event_names = NULL,
                       L0_old,
                       A0_old,
                       intervention1 = NULL,
                       intervention2 = NULL) {

  ID <- NULL

  # Data frame for storing data
  sim_data <- data.frame(ID = 1:N,
                         L0 = sample(L0_old, N, TRUE),
                         A0 = sample(A0_old, N, TRUE))

  # The cumulative hazard and inverse cumulative hazard
  y.pred <- predict(RF_fit, sim_data)                     # Cumulative hazard for simulated data
  times <-  c(0,y.pred$time.interest)                     # Time points
  tp <- length(times) - 1

  # Number of events
  num_events <- if(is.na(dim(y.pred$chf)[3])) 1 else dim(y.pred$chf)[3]
  if(!is.null(event_names)) for (name in event_names) sim_data[[name]] <- 0 else
    for (name in paste0("N", 1:num_events)) sim_data[[name]] <- 0

  # ------------------------- ICF -----------------------------------------

  # We need to be able to tell the rows from one another
  distinction <- matrix(rep(seq(1, N)*10, tp), nrow = N, ncol = tp)
  # For the adherent timepoint
  mat_add <- matrix(c(rep(0,N), rep(1,N)), ncol = 2)

  vec2mat_idx <- function(idx) {
    j <- idx %% tp
    j[j == 0] <- tp
    i <- ceiling(idx / tp)
    return(cbind(i,j))
  }

  invcumhaz_fn <- function(p, j){
    cumhazz <-  if(num_events == 1) y.pred$chf else y.pred$chf[,,j]
    cumhazz_idx <- c(transpose(cumhazz + distinction))
    p_idx <- p + seq(1,N)*10
    idx <- findInterval(p_idx, cumhazz_idx) |> vec2mat_idx()
    idx[idx[,2] == ncol(cumhazz)] <- ncol(cumhazz) - 1
    idx2 <- (idx + mat_add)
    p1 <- cumhazz[idx]; p2 <- cumhazz[idx2]
    y1 <- times[idx[,2]]; y2 <- times[idx2[,2]]
    # If the cumulative hazard flattens, we choose the smallest time
    y1 + ifelse(p1 == p2, 0, (p - p1) * (y2 - y1) / (p2 - p1))
  }

  # ------------------------- SAMPLING -----------------------------------------

  # Simulate the uniform random variable
  U <- matrix(-log(stats::runif(N * num_events)), ncol = num_events)  # matrix for the random draws

  # Find the event times
  event_times <- matrix(nrow = N, ncol = num_events)

  for(j in seq_len(num_events)) {
    event_times[,j] <- invcumhaz_fn(U[,j], j)
  }

  # The next event is the minimum of these events
  T_k <- apply(event_times, 1, min)
  Deltas <- apply(event_times, 1, which.min)

  # Update event counts
  sim_data[cbind(1:N, Deltas + 2)] <- sim_data[cbind(1:N, Deltas + 2)] + 1

  # Store data
  res <- data.table(ID = 1:N,
                    Time = T_k,
                    Delta = Deltas,
                    sim_data)

  setkey(res, ID)
  return(res)
}

func1(10^5, RF_fit, L0_old = data$L0, A0_old = data$A0)
})
```


```{r}
my_bench <- bench::press(
  N = 2^(10:12),
  {bench::mark(
    "Old" = simEventRFOld(N, RF_fit, L0_old = data$L0, A0_old = data$A0, term_events = 1, n_event_max = 1),
    "New" = simEventRF(N, RF_fit, L0_old = data$L0, A0_old = data$A0),
    check = FALSE)})

summary(my_bench)
autoplot(my_bench)
```

```{r}
time <- rep(1,10^6)

func1 <- function(time) pracma::interp1(times, c(0,cumhazz[i,]), xi = time, method = "linear")
func2 <- stats::approxfun(times, c(0, cumhazz[i,]),
                                         method="linear", yright = Inf)

bench::mark(
    "cov_at_risk" = func1(time),
    "gammel" = func2(time),
    check = FALSE)
```


Methods for substituting findinterval

```{r}

vec2mat_idx <- function(idx) {
  j <- idx %% tp
  j[j == 0] <- tp
  i <- ceiling(idx / tp)
  return(cbind(i,j))
}

invcumhaz_fn1 <- function(p, j){
  cumhazz <-  if(num_events == 1) y.pred$chf else y.pred$chf[,,j]
  cumhazz_idx <- c(t(cumhazz + distinction))
  p_idx <- p + seq(1,N)*10
  idx <- findInterval(p_idx, cumhazz_idx) |> vec2mat_idx()
  idx[idx[,2] == ncol(cumhazz)] <- ncol(cumhazz) - 1
  idx2 <- (idx + mat_add)
  p1 <- cumhazz[idx]; p2 <- cumhazz[idx2]
  y1 <- times[idx[,2]]; y2 <- times[idx2[,2]]
  # If the cumulative hazard flattens, we choose the smallest time
  y1 + ifelse(p1 == p2, 0, (p - p1) * (y2 - y1) / (p2 - p1))
}

invcumhaz_fn2 <- function(p, j){
  cumhazz <-  if(num_events == 1) y.pred$chf else y.pred$chf[,,j]
  cumhazz_idx <- c(t(cumhazz + distinction))
  p_idx <- p + seq(1,N)*10
  idx <- findInterval(p_idx, cumhazz_idx) |> vec2mat_idx()
  idx[idx[,2] == ncol(cumhazz)] <- ncol(cumhazz) - 1
  idx2 <- (idx + mat_add)
  p1 <- cumhazz[idx]; p2 <- cumhazz[idx2]
  y1 <- times[idx[,2]]; y2 <- times[idx2[,2]]
  # If the cumulative hazard flattens, we choose the smallest time
  y1 + ifelse(p1 == p2, 0, (p - p1) * (y2 - y1) / (p2 - p1))
}

```


```{r}
bench::mark(
    "new" = invcumhaz_fn2(U[,1]),
    "old" = invcumhaz_fn1(U[,1]),
    check = FALSE)
```

```{r}
profvis::profvis({
  vec2mat_idx <- function(idx) {
  j <- idx %% tp
  j[j == 0] <- tp
  i <- ceiling(idx / tp)
  return(cbind(i,j))
}

invcumhaz_fn2 <- function(p, j){
  cumhazz <-  if(num_events == 1) y.pred$chf else y.pred$chf[,,j]
  cumhazz_idx <- c(t(cumhazz + distinction))
  p_idx <- p + seq(1,N)*10
  idx <- findInterval(p_idx, cumhazz_idx) |> vec2mat_idx()
  idx[idx[,2] == ncol(cumhazz)] <- ncol(cumhazz) - 1
  idx2 <- (idx + mat_add)
  p1 <- cumhazz[idx]; p2 <- cumhazz[idx2]
  y1 <- times[idx[,2]]; y2 <- times[idx2[,2]]
  # If the cumulative hazard flattens, we choose the smallest time
  y1 + ifelse(p1 == p2, 0, (p - p1) * (y2 - y1) / (p2 - p1))
}

invcumhaz_fn2(U[,1])
})
```



