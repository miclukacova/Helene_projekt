---
title: 'Benschmarking and profiling'
output: html_document
date: "2024-10-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Libraries
library(data.table)
library(survival)
#install.packages("rtmle")
#devtools::install_github("tagteam/rtmle")
library(rtmle)
library(simevent)
library(ggplot2)
library(microbenchmark)
theme_set(theme_bw())
```

# Optimizing the simulation algorithm


```{r}
profvis::profvis({
simEventData2 <- function(N,                     # Number of individuals
                         beta = NULL,            # Effects
                         eta = NULL,             # Shape parameters
                         nu = NULL,              # Scale parameters
                         at_risk = NULL,         # Function defining the setting
                         term_deltas = c(0,1),   # Terminal events
                         max_cens = Inf,         # Followup time
                         add_cov = NULL,         # Additional baseline covariates
                         override_beta = NULL,   # Override beta
                         max_events = 10,        # Maximal events per individual
                         lower = 10^(-15),       # Lower bound for ICH
                         upper = 200,            # Upper bound for ICH
                         gen_A0 = NULL           # Generation of A0
){
  ID <- NULL

  ############################ Check and useful quantities #####################
  # Check of add_cov
  if(!(is.null(add_cov) | is.list(add_cov))){
    stop("add_cov needs to be list of random functions")
  }

  # Number of additional baseline covariates
  num_add_cov <- length(add_cov)

  # Determine number of events
  num_events <- if (!is.null(eta)) length(eta) else
    if (!is.null(nu)) length(nu) else
      if (!is.null(beta)) ncol(beta) else 4

  # Useful indices
  N_start <- 3 + num_add_cov
  N_stop <- 2 + num_add_cov + num_events

  ############################ Default values ##################################

  # Set default values for beta, eta, and nu
  beta <- if (!is.null(beta)) beta else matrix(0, nrow = N_stop, ncol = num_events)
  colnames(beta) <- paste0("N", seq(0, num_events -1))

  if((N_stop) != nrow(beta)){
    stop("Number of rows in beta should equal the sum of number of event and
         number of additional covariates + 2")
  }

  eta  <- if (!is.null(eta)) eta   else rep(0.1, num_events)
  nu   <- if (!is.null(nu)) nu     else rep(1.1, num_events)

  # Check of dimensions
  if(num_events != length(nu) || num_events != ncol(beta)){
    stop("Length of eta should be equal to nu and number of columns of beta")
  }

  # Default at_risk
  if(is.null(at_risk)){
    riskss <- rep(1, num_events)
    at_risk <- function(events) return(riskss)
  }
  # Default A0 generation
  if(is.null(gen_A0)){
    gen_A0 <- function(N, L0) stats::rbinom(N, 1, 0.5)
  }

  # Matrix for storing values
  simmatrix <- matrix(0, nrow = N, ncol = (2 + num_events + num_add_cov))

  # Generate additional covariates if distributions are specified
  if (num_add_cov != 0) {
    simmatrix[,3:(2+length(add_cov))] <- sapply(add_cov, function(f) f(N))
  }

  # Naming of matrices
  if (is.null(names(add_cov)) && num_add_cov != 0) {
    colnames(simmatrix) <- c("L0", "A0", paste0("L", seq_len(num_add_cov)), colnames(beta))
  } else {
    colnames(simmatrix) <- c("L0", "A0", names(add_cov), colnames(beta))
  }

  rownames(beta) <- colnames(simmatrix)

  # Filing out beta matrix
  if(!is.null(override_beta)){
    for (bb in 1:length(override_beta)) {
      if (names(override_beta)[bb] %in% rownames(beta)) {
        beta[bb, names(override_beta[[bb]])] <- override_beta[[bb]]
      } else {
        beta <- rbind(beta, matrix(0, nrow = 1, ncol = ncol(beta)))
        beta[nrow(beta), names(override_beta[[bb]])] <- override_beta[[bb]]
        rownames(beta)[nrow(beta)] <- names(override_beta)[bb]
      }
    }
  }

  ############################ Functions #######################################

  # Proportional hazard
  if(nrow(beta) == N_stop){
    calculate_phi <- function(simmatrix) {
      exp(simmatrix %*% beta)
    }
  } else {
    calculate_phi <- function(simmatrix) {
      obj <- as.data.frame(simmatrix)
      X <- sapply(rownames(beta), function(expr) {
        eval(parse(text = expr), envir = obj)
      })
      effects <- as.matrix(X) %*% beta
      return(exp(effects))
    }
  }

  # Intensities
  lambda <- function(t, i) {
    risk_vec <- at_risk(simmatrix[i, N_start:N_stop])
    risk_vec * eta * nu * t^(nu - 1) * phi[i,]
  }

  # If all events have the same parameter, the inverse of the cumulative hazard simplifies
  if(all(nu[1] == nu) && all(eta[1] == eta)){
    inverse_sc_haz <- function(p, t, i) {
      denom <- sum(at_risk(simmatrix[i, N_start:N_stop]) * eta * phi[i,])
      (p / denom + t^nu[1])^(1 / nu[1]) - t
    }
  # Otherwise we use a numerical inverse coded in rcpp
  } else{
    # Summed cumulative hazard
    sum_cum_haz <- function(u, t, i) {
      sum(at_risk(simmatrix[i, N_start:N_stop]) * eta * phi[i,] * ((t + u) ^ nu - t ^ nu))
      }
    
    # Inverse summed cumulative hazard function
    inverse_sc_haz <- function(p, t, i) {
      root_function <- function(u) sum_cum_haz(u, t, i) - p
      stats::uniroot(root_function, lower = lower, upper = upper)$root
    }
  }

  # Event probabilities
  probs <- function(t, i){
    if(t == max_cens) return(c(1, rep(0, (num_events - 1))))
    probs <- lambda(t, i)
    summ <- sum(probs)
    probs / summ
  }

  ############################ Initializing Simulations ########################

  # Draw baseline covariates
  simmatrix[,1] <- stats::runif(N)                   # L0
  simmatrix[,2] <- gen_A0(N, simmatrix[,1])          # A0

  # Initialize
  T_k <- rep(0,N)                                    # Time 0
  alive <- 1:N                                       # Keeping track of who is alive
  res_list <- vector("list", max_events)             # For results
  idx <- 1                                           # Index


  ############################ Simulations #####################################

  while(length(alive) != 0){
    # Simulate time
    V <- -log(stats::runif(N))
    phi <- calculate_phi(simmatrix)
    W <- sapply(alive, function(i) inverse_sc_haz(V[i], T_k[i], i))
    T_k[alive] <- T_k[alive] + W

    # Maximal censoring time
    T_k[T_k > max_cens] <- max_cens

    # Simulate event
    probs_mat <- sapply(alive, function(i) probs(T_k[i], i), simplify = "array")
    Deltas <- sampleEvents(probs_mat)

    # Update event counts
    simmatrix[cbind(alive, 2 + num_add_cov + Deltas + 1)] <-
      simmatrix[cbind(alive, 2 + num_add_cov + Deltas + 1)] + 1

    # Store data
    kth_event <- data.table(ID = alive,
                            Time = T_k[alive],
                            Delta = Deltas)

    res_list[[idx]] <- cbind(kth_event, data.table::as.data.table(simmatrix[alive, , drop = FALSE]))
    idx <- idx + 1

    # Who is still alive and uncensored?
    alive <- alive[!Deltas %in% term_deltas]
  }

  res <- data.table::rbindlist(res_list)
  setkey(res, ID)

  return(res)
}

  #simEventData2(N = 10000)
  simEventData2(N = 10^4, eta = c(0.1,0.1,0.2,0.1))
  #simEventData2(N = 5000, override_beta = list("N2>=1" = c("N1" = 1.2)))
})
```

Matrix multiplikationen, den inverse 

```{r}
my_bench <- bench::press(
  N = seq(1000, 3000, by = 500),
  {
    bench::mark(
      "simEventData" = simEventData(N = N, eta = c(0.1,0.1,0.2,0.1)),
      "simEventData2" = simEventData2(N = N, eta = c(0.1,0.1,0.2,0.1)),
      #"simEventData3" = simEventData3(N = N, override_beta = list("N2>=1" = c("N1" = 1.2))),
      check = FALSE
    )
  }
)

my_bench |>
  dplyr::mutate(expr = as.character(expression), median = as.numeric(median)) |> 
  ggplot(aes(N, median, color = expr)) + geom_point() + 
  #scale_y_log10() +
  geom_line() + labs(y = "time (ms)")
```


```{r}
simmatrix <- matrix(0, nrow = N, ncol = (2 + 3 + 4))
beta <- matrix(0, nrow = 9, ncol = 3)


library(microbenchmark)
microbenchmark(
  twoStep = {
    effects <- simmatrix %*% beta
    exp(effects)},
  allInOne = {
    exp(simmatrix %*% beta)
  },
  times = 100
)

my_bench |>
  dplyr::mutate(expr = as.character(expression), median = as.numeric(median)) |> 
  ggplot(aes(N, median, color = expr)) + geom_point() + 
  #scale_y_log10() +
  geom_line() + labs(y = "time (ms)")
```



# Profiling simEventCox

```{r}
set.seed(373)
data <- simT2D(N = 5000, beta_L0_L = 1, beta_L0_D = 1, beta_L_D = 0.5, beta_A0_L = 1)
# Transform data into tstart tstop format
data_int <- IntFormatData(data, N_cols = 6)

# Fit Cox models
cox_death <- coxph(Surv(tstart, tstop, Delta == 1) ~ L0 + A0 + L, data = data_int)
cox_t2d <- coxph(Surv(tstart, tstop, Delta == 2) ~ L0 + A0, data = data_int[L == 0])
cox_fits <- list("D" = cox_death, "L" = cox_t2d)

profvis::profvis({
simEventCox <- function(N,
                        cox_fits,
                        L0_old,
                        A0_old,
                        max_events = 5,
                        n_event_max = c(1,1),
                        term_events = 1,
                        intervention = NULL) {

  ID <- NULL

  # Initialize
  num_events <- length(cox_fits)                          # Number of events
  alive <- 1:N                                            # Vector for keeping track of who is alive
  num_alive <- N                                          # Number of alive individuals
  T_k <- rep(0, N)                                        # Last event time

  # Data frame for storing data
  sim_data <- data.frame(L0 = sample(L0_old, N, TRUE),
                         A0 = sample(A0_old, N, TRUE))
  for (name in names(cox_fits)) sim_data[[name]] <- 0

  # List for results
  res_list <- vector("list", max_events)                  # For results
  idx <- 1                                                # Index

  # Base hazard
  basehazz_list <- lapply(cox_fits, function(model) basehaz(model, centered = FALSE))

  # The cumulative hazard and inverse cumulative hazard
  cumhaz_fn <- vector("list", num_events)
  invhaz_fn <- vector("list", num_events)
  for(j in seq_len(num_events)) {
    H_j <- c(0, basehazz_list[[j]][["hazard"]])
    t_j <- c(0, basehazz_list[[j]][["time"]])
    cumhaz_fn[[j]] <- stats::approxfun(t_j,       H_j,
                                       method="linear", yright = Inf)
    # We choose ties = max to ensure that event times are strictly increasing
    invhaz_fn[[j]] <- stats::approxfun(H_j,       t_j,
                                       method="linear", rule=2, ties = max)
  }

  # Loop
  while(num_alive != 0){
    # Intervention Cox term
    if(!is.null(intervention)){
      cox_term <- list()
      for(j in seq_len(num_events)){
        sim_data_cox <- intervention(j, sim_data)
        cox_term[[j]] <- exp(stats::predict(cox_fits[[j]], newdata = sim_data_cox, type="lp", reference = "zero"))
        }
      # Calculate the non intervention Cox term
      } else{
      cox_term <- lapply(cox_fits, function(model)
        exp(stats::predict(model, newdata = sim_data, type="lp", reference = "zero")))
    }

    # Calculate the cumulative intensity per individual per event
    cum_int_Tk <- sapply(seq_len(num_events), function(j) {
      cumhaz_fn[[j]](T_k) * cox_term[[j]]
    })

    # Simulate the uniform random variable
    U <- matrix(-log(stats::runif(num_alive * num_events)), ncol = num_events)  # matrix for the random draws
    V <- U + cum_int_Tk

    # Find the event times
    event_times <- sapply(seq_len(num_events), function(j) {
      invhaz_fn[[j]](V[,j] / cox_term[[j]])
    })

    # How many times can you experience the various events?
    for(j in seq_len(num_events)){
      event_times[sim_data[, (2+j)] == n_event_max[j], j] <- Inf
    }

    # The next event is the minimum of these events
    T_k <- apply(event_times, 1, min)
    Deltas <- apply(event_times, 1, which.min)

    # Update event counts
    #for(i in 1:num_alive){
    #  sim_data[i, (Deltas[i] + 2)] <- sim_data[i, (Deltas[i] + 2)] + 1
    #}
    sim_data[cbind(seq_len(num_alive), Deltas + 2)] <- sim_data[cbind(seq_len(num_alive), Deltas + 2)] + 1

    # Store data
    kth_event <- data.table(ID = alive,
                            Time = T_k,
                            Delta = Deltas)

    res_list[[idx]] <- cbind(kth_event, data.table::as.data.table(sim_data))
    idx <- idx + 1

    # Who is still alive?
    alive <- alive[!(Deltas %in% term_events)]
    num_alive <- length(alive)
    # For the next iteration we only keep data from individuals alive
    T_k <- T_k[!(Deltas %in% term_events)]
    sim_data <- sim_data[!(Deltas %in% term_events), , drop = FALSE]
  }

  res <- data.table::rbindlist(res_list)
  setkey(res, ID)
  return(res)
}
simEventCox(5000, cox_fits, L0_old = data$L0, A0_old = data$A0)
})
```





